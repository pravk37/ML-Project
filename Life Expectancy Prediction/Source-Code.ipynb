{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\bogip\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\bogip\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\bogip\\anaconda3\\lib\\site-packages (from xgboost) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bogip\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\bogip\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\bogip\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\bogip\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bogip\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000191D8C576D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tinker/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000191D8BF6C10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tinker/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000191D8BF4190>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tinker/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000191D8C9BF10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tinker/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000191D8C94990>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tinker/\n",
      "ERROR: Could not find a version that satisfies the requirement tinker (from versions: none)\n",
      "ERROR: No matching distribution found for tinker\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\bogip\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bogip\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\bogip\\anaconda3\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: keras in c:\\users\\bogip\\anaconda3\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\bogip\\anaconda3\\lib\\site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "!pip install scikit-learn\n",
    "!pip install pandas scikit-learn tensorflow keras numpy tinker\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def generate_data_entry():\n",
    "    data = {}\n",
    "\n",
    "    # Meals, Pulses, Rice, Protein \n",
    "    data['Meals/Day'] = random.randint(2, 4) \n",
    "    data['Pulses(g)'] = random.randint(50, 200) \n",
    "    data['Rice(g)'] = random.randint(50, 150) \n",
    "    data['Protein(g)'] = random.randint(40, 80)\n",
    "\n",
    "    # Alcohol (influenced slightly by exercise)\n",
    "    exercise_level = random.choices(['Low', 'Moderate', 'High'], weights=[35, 50, 15])[0]\n",
    "    alcohol_weights = [50, 30, 15, 5]  # Default\n",
    "    if exercise_level == 'Low':\n",
    "        alcohol_weights = [40, 35, 20, 5] \n",
    "    data['Alcohol(g)'] = random.choices([0, 5, 15, 30], weights=alcohol_weights)[0] \n",
    "\n",
    "    # Other Diet, Exercise, Sleep \n",
    "    data['Veg(g)'] = random.randint(100, 250) \n",
    "    data['Fruit(g)'] = random.randint(50, 150) \n",
    "    data['Processed Food(g)'] = random.randint(20, 80)\n",
    "    data['Exercise (hrs/week)'] = round(random.uniform(2.5, 6), 2) \n",
    "    data['Sleep (hrs/night)'] = round(random.uniform(6.5, 8), 2)\n",
    "\n",
    "    # Smoker (influenced slightly by exercise)\n",
    "    if exercise_level == 'Low':\n",
    "        data['Smoker (Y/N)'] = 'Y' if random.random() < 0.25 else 'N' \n",
    "    else:\n",
    "        data['Smoker (Y/N)'] = 'Y' if random.random() < 0.2 else 'N' \n",
    "\n",
    "    # Age (Concentrated in 20-50 range)\n",
    "    data['Age'] = random.randint(20, 50) \n",
    "\n",
    "    # Life Expectancy \n",
    "    base_expectancy = random.randint(data['Age'] + 20, 90)  # Minimum 20 years more\n",
    "\n",
    "    # Modifiers (with adjustments for very negative cases)\n",
    "    if data['Alcohol(g)'] > 15:\n",
    "        modifier = random.randint(10, 18) \n",
    "        base_expectancy -= modifier if base_expectancy > modifier else 5 \n",
    "    if data['Processed Food(g)'] > 60: \n",
    "        modifier = random.randint(6, 12)\n",
    "        base_expectancy -= modifier if base_expectancy > modifier else 3 \n",
    "    if data['Smoker (Y/N)'] == 'Y':\n",
    "        modifier = random.randint(12, 20)\n",
    "        base_expectancy -= modifier if base_expectancy > modifier else 8\n",
    "    if data['Exercise (hrs/week)'] < 4:\n",
    "        modifier = random.randint(5, 10)\n",
    "        base_expectancy -= modifier if base_expectancy > modifier else 3 \n",
    "    if data['Alcohol(g)'] > 15 and data['Smoker (Y/N)'] == 'Y': \n",
    "        modifier = random.randint(5, 10)\n",
    "        base_expectancy -= modifier if base_expectancy > modifier else 2\n",
    "\n",
    "    # Ensure life expectancy is always greater than or equal to age\n",
    "    data['Life Expectancy'] = max(base_expectancy, data['Age'] + 5)  \n",
    "\n",
    "    # Other Factors\n",
    "    stress_level = random.choices(['Low', 'Medium', 'High'], weights=[40, 45, 15])[0]\n",
    "    if stress_level == 'Medium':\n",
    "        base_expectancy -= random.randint(0, 3)\n",
    "    elif stress_level == 'High':\n",
    "        base_expectancy -= random.randint(3, 6)\n",
    "    has_condition = random.choices(['Yes', 'No'], weights=[30, 70])[0]\n",
    "    if has_condition == 'Yes':\n",
    "        base_expectancy -= random.randint(5, 15)\n",
    "\n",
    "    data['Stress Level'] = stress_level \n",
    "    data['Pre-Existing Conditions (Y/N)'] = has_condition\n",
    "\n",
    "    return data\n",
    "\n",
    "# Generate data and save to CSV\n",
    "data = []\n",
    "for _ in range(500):  \n",
    "    data.append(generate_data_entry())\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"diet_and_lifestyle_data.csv\", index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# # Load the Data\n",
    "# df = pd.read_csv(\"diet_and_lifestyle_data.csv\") \n",
    "\n",
    "# # Handle Categorical Features\n",
    "\n",
    "# # Option 1: One-Hot Encoding \n",
    "# encoder = OneHotEncoder(handle_unknown='ignore')  # To handle unseen categories in new data \n",
    "# smoker_encoded = encoder.fit_transform(df[['Smoker (Y/N)']])\n",
    "# stress_encoded = encoder.fit_transform(df[['Stress Level']]) \n",
    "# preexisting_encoded = encoder.fit_transform(df[['Pre-Existing Conditions (Y/N)']])\n",
    "\n",
    "# # Create new DataFrame with encoded columns\n",
    "# df_encoded = pd.DataFrame(smoker_encoded.toarray(), columns=[\"Smoker_No\", \"Smoker_Yes\"]) \n",
    "# df_encoded = pd.concat([df_encoded, pd.DataFrame(stress_encoded.toarray(), columns=[\"Stress_Low\", \"Stress_Medium\", \"Stress_High\"])], axis=1)\n",
    "# df_encoded = pd.concat([df_encoded, pd.DataFrame(preexisting_encoded.toarray(), columns=[\"PreExisting_No\", \"PreExisting_Yes\"])], axis=1)\n",
    "\n",
    "# # Drop original columns and join the encoded data\n",
    "# df = df.drop(['Smoker (Y/N)', 'Stress Level', 'Pre-Existing Conditions (Y/N)'], axis=1)\n",
    "# df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# # Option 2: Label Encoding (Use with caution)\n",
    "# encoder = LabelEncoder()\n",
    "# df['Smoker (Y/N)'] = encoder.fit_transform(df['Smoker (Y/N)'])  \n",
    "# df['Stress Level'] = encoder.fit_transform(df['Stress Level']) \n",
    "# df['Pre-Existing Conditions (Y/N)'] = encoder.fit_transform(df['Pre-Existing Conditions (Y/N)']) \n",
    "\n",
    "# # ... (Rest of your preprocessing, if needed) ...\n",
    "# # ... (Previous code for loading and encoding) ...\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Assuming you want to scale numerical features\n",
    "# scaler = StandardScaler()\n",
    "# df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']] = scaler.fit_transform(df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']])\n",
    "\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split data \n",
    "# X = df.drop('Life Expectancy', axis=1)\n",
    "# y = df['Life Expectancy']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "# # Create and train model\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Evaluate\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error:\", mse) \n",
    "# # KNN\n",
    "# # knn_model = KNeighborsRegressor(n_neighbors=5)  # You might need to experiment with n_neighbors\n",
    "# # knn_model.fit(X_train, y_train)\n",
    "\n",
    "# # # Linear Regression (We already did this in the previous example)\n",
    "# # lr_model = LinearRegression()\n",
    "# # lr_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINER REGRESION AND KNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - Mean Squared Error: 109.96026790960414\n",
      "KNN - Mean Squared Error: 226.5664\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Data\n",
    "df = pd.read_csv(\"diet_and_lifestyle_data.csv\") \n",
    "\n",
    "# Handle Categorical Features (One-Hot Encoding)\n",
    "encoder = OneHotEncoder(handle_unknown='ignore') \n",
    "smoker_encoded = encoder.fit_transform(df[['Smoker (Y/N)']])\n",
    "stress_encoded = encoder.fit_transform(df[['Stress Level']]) \n",
    "preexisting_encoded = encoder.fit_transform(df[['Pre-Existing Conditions (Y/N)']])\n",
    "\n",
    "df_encoded = pd.DataFrame(smoker_encoded.toarray(), columns=[\"Smoker_No\", \"Smoker_Yes\"]) \n",
    "df_encoded = pd.concat([df_encoded, pd.DataFrame(stress_encoded.toarray(), columns=[\"Stress_Low\", \"Stress_Medium\", \"Stress_High\"])], axis=1)\n",
    "df_encoded = pd.concat([df_encoded, pd.DataFrame(preexisting_encoded.toarray(), columns=[\"PreExisting_No\", \"PreExisting_Yes\"])], axis=1)\n",
    "\n",
    "df = df.drop(['Smoker (Y/N)', 'Stress Level', 'Pre-Existing Conditions (Y/N)'], axis=1)\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']] = scaler.fit_transform(df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']])\n",
    "\n",
    "# Split data \n",
    "X = df.drop('Life Expectancy', axis=1)\n",
    "y = df['Life Expectancy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred = lr_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Linear Regression - Mean Squared Error:\", mse) \n",
    "\n",
    "# KNN\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5) \n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"KNN - Mean Squared Error:\", mse) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN WITH PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pickle \n",
    "\n",
    "# Load the Data\n",
    "df = pd.read_csv(\"diet_and_lifestyle_data.csv\") \n",
    "\n",
    "# Handle Categorical Features (One-Hot Encoding)\n",
    "encoder = OneHotEncoder(handle_unknown='ignore') \n",
    "smoker_encoded = encoder.fit_transform(df[['Smoker (Y/N)']])\n",
    "stress_encoded = encoder.fit_transform(df[['Stress Level']]) \n",
    "preexisting_encoded = encoder.fit_transform(df[['Pre-Existing Conditions (Y/N)']])\n",
    "\n",
    "df_encoded = pd.DataFrame(smoker_encoded.toarray(), columns=[\"Smoker_No\", \"Smoker_Yes\"]) \n",
    "df_encoded = pd.concat([df_encoded, pd.DataFrame(stress_encoded.toarray(), columns=[\"Stress_Low\", \"Stress_Medium\", \"Stress_High\"])], axis=1)\n",
    "df_encoded = pd.concat([df_encoded, pd.DataFrame(preexisting_encoded.toarray(), columns=[\"PreExisting_No\", \"PreExisting_Yes\"])], axis=1)\n",
    "\n",
    "df = df.drop(['Smoker (Y/N)', 'Stress Level', 'Pre-Existing Conditions (Y/N)'], axis=1)\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']] = scaler.fit_transform(df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']])\n",
    "\n",
    "# Split data \n",
    "X = df.drop('Life Expectancy', axis=1)\n",
    "y = df['Life Expectancy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "# KNN Hyperparameter Tuning\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9, 11]} \n",
    "knn = KNeighborsRegressor()\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5) \n",
    "grid_search.fit(X_train, y_train)\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# Save the model\n",
    "with open('life_expectancy_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_knn, f)\n",
    "def predict_life_expectancy(new_data):\n",
    "    \"\"\"Takes a dictionary of user input and predicts life expectancy.\n",
    "\n",
    "    Args:\n",
    "        new_data (dict): Dictionary containing user input for all features.\n",
    "\n",
    "    Returns:\n",
    "        float: Predicted life expectancy.\n",
    "    \"\"\"\n",
    "\n",
    "    new_df = pd.DataFrame(new_data, index=[0])  \n",
    "\n",
    "    # One-Hot Encoding (consistent with training data)\n",
    "    new_df = pd.concat([new_df, pd.get_dummies(new_df['Smoker (Y/N)'], prefix='Smoker')], axis=1)\n",
    "    new_df = pd.concat([new_df, pd.get_dummies(new_df['Stress Level'], prefix='Stress')], axis=1)\n",
    "    new_df = pd.concat([new_df, pd.get_dummies(new_df['Pre-Existing Conditions (Y/N)'], prefix='PreExisting')], axis=1)\n",
    "    new_df = new_df.drop(['Smoker (Y/N)', 'Stress Level', 'Pre-Existing Conditions (Y/N)'], axis=1)\n",
    "\n",
    "    # Ensure consistent columns\n",
    "    missing_cols = set(X.columns) - set(new_df.columns)\n",
    "    for col in missing_cols:\n",
    "        new_df[col] = 0\n",
    "\n",
    "    new_df = new_df[X.columns]  # Reorder columns\n",
    "\n",
    "    # Scaling (using the scaler fitted on training data)\n",
    "    new_df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']] = scaler.transform(new_df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']])\n",
    "\n",
    "    # Load the saved model\n",
    "    with open('life_expectancy_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(new_df)\n",
    "    return prediction[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 197.01285714285714\n",
      "Root Mean Squared Error: 14.036126856895287\n",
      "Mean Absolute Error: 11.527142857142858\n",
      "R-squared: 0.1756960117467905\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pickle\n",
    "\n",
    "# Load the Data\n",
    "df = pd.read_csv(\"diet_and_lifestyle_data.csv\")\n",
    "\n",
    "# Handle Categorical Features (One-Hot Encoding)\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "smoker_encoded = encoder.fit_transform(df[['Smoker (Y/N)']])\n",
    "stress_encoded = encoder.fit_transform(df[['Stress Level']])\n",
    "preexisting_encoded = encoder.fit_transform(df[['Pre-Existing Conditions (Y/N)']])\n",
    "\n",
    "df_encoded = pd.DataFrame(smoker_encoded.toarray(), columns=[\"Smoker_No\", \"Smoker_Yes\"])\n",
    "df_encoded = pd.concat([df_encoded, pd.DataFrame(stress_encoded.toarray(), columns=[\"Stress_Low\", \"Stress_Medium\", \"Stress_High\"])], axis=1)\n",
    "df_encoded = pd.concat([df_encoded, pd.DataFrame(preexisting_encoded.toarray(), columns=[\"PreExisting_No\", \"PreExisting_Yes\"])], axis=1)\n",
    "\n",
    "df = df.drop(['Smoker (Y/N)', 'Stress Level', 'Pre-Existing Conditions (Y/N)'], axis=1)\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']] = scaler.fit_transform(df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']])\n",
    "\n",
    "# Split data\n",
    "X = df.drop('Life Expectancy', axis=1)\n",
    "y = df['Life Expectancy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# KNN Hyperparameter Tuning\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9, 11]}\n",
    "knn = KNeighborsRegressor()\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)  # Root MSE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Save the model\n",
    "with open('knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_knn, f)\n",
    "\n",
    "def predict_life_expectancy(new_data):\n",
    "    \"\"\"Predicts life expectancy based on a dictionary of user input.\n",
    "\n",
    "    Args:\n",
    "        new_data (dict): Dictionary containing user input for all features.\n",
    "\n",
    "    Returns:\n",
    "        float: Predicted life expectancy.\n",
    "    \"\"\"\n",
    "\n",
    "    new_df = pd.DataFrame(new_data, index=[0])\n",
    "\n",
    "    # One-Hot Encoding (consistent with training data)\n",
    "    new_df = pd.concat([new_df, pd.get_dummies(new_df['Smoker (Y/N)'], prefix='Smoker')], axis=1)\n",
    "    new_df = pd.concat([new_df, pd.get_dummies(new_df['Stress Level'], prefix='Stress')], axis=1)\n",
    "    new_df = pd.concat([new_df, pd.get_dummies(new_df['Pre-Existing Conditions (Y/N)'], prefix='PreExisting')], axis=1)\n",
    "    new_df = new_df.drop(['Smoker (Y/N)', 'Stress Level', 'Pre-Existing Conditions (Y/N)'], axis=1)\n",
    "\n",
    "    # Ensure consistent columns\n",
    "    missing_cols = set(X.columns) - set(new_df.columns)\n",
    "    for col in missing_cols:\n",
    "        new_df[col] = 0\n",
    "\n",
    "    new_df = new_df[X.columns]  # Reorder columns\n",
    "\n",
    "    # Scaling (using the scaler fitted on training data)\n",
    "    new_df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']] = scaler.transform(new_df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']])\n",
    "\n",
    "    # Load the saved model\n",
    "    with open('knn_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(new_df)\n",
    "    return int(prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dl modles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dense network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bogip\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 4251.3525 - rmse: 65.1966 - val_loss: 3942.5933 - val_rmse: 62.7901\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4126.8169 - rmse: 64.2391 - val_loss: 3894.5242 - val_rmse: 62.4061\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4046.3218 - rmse: 63.6081 - val_loss: 3839.3320 - val_rmse: 61.9623\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3849.9993 - rmse: 62.0356 - val_loss: 3772.4321 - val_rmse: 61.4201\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3902.7400 - rmse: 62.4707 - val_loss: 3691.9688 - val_rmse: 60.7616\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3789.5137 - rmse: 61.5511 - val_loss: 3594.2212 - val_rmse: 59.9518\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3592.3569 - rmse: 59.9123 - val_loss: 3474.8450 - val_rmse: 58.9478\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3517.5569 - rmse: 59.3063 - val_loss: 3330.0112 - val_rmse: 57.7062\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3350.6318 - rmse: 57.8829 - val_loss: 3157.2859 - val_rmse: 56.1897\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3141.0291 - rmse: 56.0427 - val_loss: 2955.0259 - val_rmse: 54.3601\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3093.1375 - rmse: 55.6049 - val_loss: 2719.6130 - val_rmse: 52.1499\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2861.9648 - rmse: 53.4817 - val_loss: 2458.6125 - val_rmse: 49.5844\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2468.4451 - rmse: 49.6818 - val_loss: 2173.6743 - val_rmse: 46.6227\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2326.4807 - rmse: 48.2053 - val_loss: 1870.1168 - val_rmse: 43.2448\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1903.3657 - rmse: 43.6217 - val_loss: 1561.9575 - val_rmse: 39.5216\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1597.6808 - rmse: 39.9524 - val_loss: 1258.7782 - val_rmse: 35.4793\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1282.3245 - rmse: 35.7925 - val_loss: 974.0871 - val_rmse: 31.2104\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1037.8118 - rmse: 32.1828 - val_loss: 721.5944 - val_rmse: 26.8625\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 726.8251 - rmse: 26.9478 - val_loss: 517.8527 - val_rmse: 22.7564\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 532.4381 - rmse: 23.0560 - val_loss: 360.3360 - val_rmse: 18.9825\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 383.1239 - rmse: 19.5630 - val_loss: 252.0283 - val_rmse: 15.8754\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 282.4609 - rmse: 16.7955 - val_loss: 186.4172 - val_rmse: 13.6535\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 218.8980 - rmse: 14.7923 - val_loss: 151.5737 - val_rmse: 12.3115\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 176.8965 - rmse: 13.2939 - val_loss: 135.2495 - val_rmse: 11.6297\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 168.8619 - rmse: 12.9916 - val_loss: 127.4115 - val_rmse: 11.2877\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 155.0782 - rmse: 12.4502 - val_loss: 124.2846 - val_rmse: 11.1483\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 154.5901 - rmse: 12.4310 - val_loss: 122.5259 - val_rmse: 11.0691\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 132.1422 - rmse: 11.4902 - val_loss: 120.9144 - val_rmse: 10.9961\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 127.1003 - rmse: 11.2506 - val_loss: 119.9094 - val_rmse: 10.9503\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 123.5605 - rmse: 11.1069 - val_loss: 118.8288 - val_rmse: 10.9009\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 123.2413 - rmse: 11.0925 - val_loss: 118.2108 - val_rmse: 10.8725\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 135.9862 - rmse: 11.6585 - val_loss: 117.9460 - val_rmse: 10.8603\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 129.7192 - rmse: 11.3864 - val_loss: 117.1845 - val_rmse: 10.8252\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 133.9288 - rmse: 11.5692 - val_loss: 116.4580 - val_rmse: 10.7916\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 117.2818 - rmse: 10.8225 - val_loss: 116.2822 - val_rmse: 10.7834\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 120.9750 - rmse: 10.9934 - val_loss: 115.8291 - val_rmse: 10.7624\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 130.5583 - rmse: 11.4186 - val_loss: 115.5372 - val_rmse: 10.7488\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 125.4642 - rmse: 11.1936 - val_loss: 114.7916 - val_rmse: 10.7141\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 122.9227 - rmse: 11.0836 - val_loss: 114.7107 - val_rmse: 10.7103\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 115.4905 - rmse: 10.7406 - val_loss: 114.5047 - val_rmse: 10.7007\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 102.7786 - rmse: 10.1204 - val_loss: 114.1790 - val_rmse: 10.6855\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 103.3218 - rmse: 10.1389 - val_loss: 114.0011 - val_rmse: 10.6771\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 120.2838 - rmse: 10.9644 - val_loss: 113.1635 - val_rmse: 10.6378\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 125.1295 - rmse: 11.1778 - val_loss: 112.6016 - val_rmse: 10.6114\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 123.1666 - rmse: 11.0837 - val_loss: 112.8808 - val_rmse: 10.6245\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 116.5268 - rmse: 10.7863 - val_loss: 112.0988 - val_rmse: 10.5877\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 120.9552 - rmse: 10.9920 - val_loss: 112.5264 - val_rmse: 10.6078\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 109.7644 - rmse: 10.4725 - val_loss: 110.9962 - val_rmse: 10.5355\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 105.1428 - rmse: 10.2424 - val_loss: 112.0592 - val_rmse: 10.5858\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 105.9905 - rmse: 10.2860 - val_loss: 111.3764 - val_rmse: 10.5535\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 121.3203 - rmse: 10.9941 - val_loss: 111.1151 - val_rmse: 10.5411\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 109.2239 - rmse: 10.4425 - val_loss: 110.9646 - val_rmse: 10.5340\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 115.1995 - rmse: 10.7307 - val_loss: 110.8985 - val_rmse: 10.5308\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 115.8131 - rmse: 10.7594 - val_loss: 110.8120 - val_rmse: 10.5267\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 115.9356 - rmse: 10.7547 - val_loss: 110.3878 - val_rmse: 10.5066\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 113.8119 - rmse: 10.6666 - val_loss: 110.6204 - val_rmse: 10.5176\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 103.0605 - rmse: 10.1495 - val_loss: 110.7494 - val_rmse: 10.5238\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 113.3146 - rmse: 10.6433 - val_loss: 110.7916 - val_rmse: 10.5258\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 100.3977 - rmse: 10.0101 - val_loss: 110.2207 - val_rmse: 10.4986\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 115.8919 - rmse: 10.7601 - val_loss: 110.8646 - val_rmse: 10.5292\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 108.7554 - rmse: 10.4245 - val_loss: 110.8968 - val_rmse: 10.5308\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 108.1913 - rmse: 10.3984 - val_loss: 110.0548 - val_rmse: 10.4907\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 106.5560 - rmse: 10.3210 - val_loss: 110.0114 - val_rmse: 10.4886\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 102.7766 - rmse: 10.1306 - val_loss: 109.3782 - val_rmse: 10.4584\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 106.5816 - rmse: 10.3216 - val_loss: 110.4528 - val_rmse: 10.5097\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 107.4139 - rmse: 10.3621 - val_loss: 110.2134 - val_rmse: 10.4983\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 112.3987 - rmse: 10.5971 - val_loss: 109.7396 - val_rmse: 10.4757\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 104.7972 - rmse: 10.2356 - val_loss: 108.9498 - val_rmse: 10.4379\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 99.0172 - rmse: 9.9440 - val_loss: 109.7330 - val_rmse: 10.4754\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 112.9256 - rmse: 10.6173 - val_loss: 109.8228 - val_rmse: 10.4796\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 109.1524 - rmse: 10.4387 - val_loss: 109.9896 - val_rmse: 10.4876\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 108.9220 - rmse: 10.4278 - val_loss: 110.1447 - val_rmse: 10.4950\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 104.9433 - rmse: 10.2416 - val_loss: 109.3061 - val_rmse: 10.4550\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 108.8060 - rmse: 10.4122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 119.6838150024414\n",
      "RMSE: 10.940010070800781\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the Data\n",
    "df = pd.read_csv(\"diet_and_lifestyle_data.csv\")\n",
    "\n",
    "# Handle Categorical Features (One-Hot Encoding)\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "smoker_encoded = encoder.fit_transform(df[['Smoker (Y/N)']])\n",
    "stress_encoded = encoder.fit_transform(df[['Stress Level']])\n",
    "preexisting_encoded = encoder.fit_transform(df[['Pre-Existing Conditions (Y/N)']])\n",
    "\n",
    "df_encoded = pd.DataFrame(smoker_encoded.toarray(), columns=[\"Smoker_No\", \"Smoker_Yes\"])\n",
    "df_encoded = pd.concat([df_encoded, pd.DataFrame(stress_encoded.toarray(), columns=[\"Stress_Low\", \"Stress_Medium\", \"Stress_High\"])], axis=1)\n",
    "df_encoded = pd.concat([df_encoded, pd.DataFrame(preexisting_encoded.toarray(), columns=[\"PreExisting_No\", \"PreExisting_Yes\"])], axis=1)\n",
    "\n",
    "df = df.drop(['Smoker (Y/N)', 'Stress Level', 'Pre-Existing Conditions (Y/N)'], axis=1)\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']] = scaler.fit_transform(df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']])\n",
    "\n",
    "# Split data\n",
    "X = df.drop('Life Expectancy', axis=1)\n",
    "y = df['Life Expectancy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dense Model Architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],))) \n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1)) \n",
    "\n",
    "# Compilation (with explicit optimizer)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=[RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=5,          # Stop if no improvement for 5 epochs\n",
    "    restore_best_weights=True  # Restore model with the best weights \n",
    ")\n",
    "\n",
    "# Training (with the early stopping callback)\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluation\n",
    "loss, rmse = model.evaluate(X_test, y_test)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# Saving the model (Optional)\n",
    "model.save('dense_model.h5')\n",
    "\n",
    "# Prediction function \n",
    "def predict_life_expectancy(new_data):\n",
    "    \"\"\"Predicts life expectancy based on a dictionary of user input.\n",
    "    \"\"\"\n",
    "    new_df = pd.DataFrame(new_data, index=[0])\n",
    "\n",
    "    # One-Hot Encoding (consistent with training data)\n",
    "    new_df = pd.concat([new_df, pd.get_dummies(new_df['Smoker (Y/N)'], prefix='Smoker')], axis=1)\n",
    "    new_df = pd.concat([new_df, pd.get_dummies(new_df['Stress Level'], prefix='Stress')], axis=1)\n",
    "    new_df = pd.concat([new_df, pd.get_dummies(new_df['Pre-Existing Conditions (Y/N)'], prefix='PreExisting')], axis=1)\n",
    "    new_df = new_df.drop(['Smoker (Y/N)', 'Stress Level', 'Pre-Existing Conditions (Y/N)'], axis=1)\n",
    "\n",
    "    # Ensure consistent columns and scaling\n",
    "    missing_cols = set(X.columns) - set(new_df.columns)\n",
    "    for col in missing_cols:\n",
    "        new_df[col] = 0\n",
    "    new_df = new_df[X.columns] \n",
    "    new_df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']] = scaler.transform(new_df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']])\n",
    "\n",
    "    prediction = model.predict(new_df)\n",
    "    return int (prediction[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dl-2 imporvised dense netwrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Experimentation\u001b[39;00m\n\u001b[0;32m     51\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 52\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model((X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],))\n\u001b[0;32m     53\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_rmse\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[0;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[early_stopping]) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_model' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the Data\n",
    "df = pd.read_csv(\"diet_and_lifestyle_data.csv\")\n",
    "\n",
    "# Handle Categorical Features (One-Hot Encoding)\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "smoker_encoded = encoder.fit_transform(df[['Smoker (Y/N)']])\n",
    "stress_encoded = encoder.fit_transform(df[['Stress Level']])\n",
    "preexisting_encoded = encoder.fit_transform(df[['Pre-Existing Conditions (Y/N)']])\n",
    "\n",
    "df_encoded = pd.DataFrame(smoker_encoded.toarray(), columns=[\"Smoker_No\", \"Smoker_Yes\"])\n",
    "df_encoded = pd.concat([df_encoded, pd.DataFrame(stress_encoded.toarray(), columns=[\"Stress_Low\", \"Stress_Medium\", \"Stress_High\"])], axis=1)\n",
    "df_encoded = pd.concat([df_encoded, pd.DataFrame(preexisting_encoded.toarray(), columns=[\"PreExisting_No\", \"PreExisting_Yes\"])], axis=1)\n",
    "\n",
    "df = df.drop(['Smoker (Y/N)', 'Stress Level', 'Pre-Existing Conditions (Y/N)'], axis=1)\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Split data\n",
    "X = df.drop('Life Expectancy', axis=1)\n",
    "y = df['Life Expectancy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build Model\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "\n",
    "def build_improved_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=input_shape),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error','mean_squared_error'])    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Experimentation\n",
    "results = {}\n",
    "model = build_model((X_train.shape[1],))\n",
    "early_stopping = EarlyStopping(monitor='val_rmse', patience=15, restore_best_weights=True) \n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_split=0.2, callbacks=[early_stopping]) \n",
    "\n",
    "loss, rmse = model.evaluate(X_test, y_test)\n",
    "results['MLP'] = {'loss': loss, 'rmse': rmse}\n",
    "\n",
    "# Print Results\n",
    "print(\"Experiment Results:\")\n",
    "best_model = min(results, key=lambda k: results[k]['rmse'])\n",
    "print(f\"Best Model: {best_model}\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: Loss - {metrics['loss']}, RMSE - {metrics['rmse']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main ML CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "import xgboost as xgb \n",
    "\n",
    "# Load the Data\n",
    "df = pd.read_csv(\"diet_and_lifestyle_data.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "import xgboost as xgb \n",
    "\n",
    "# Load the Data\n",
    "df = pd.read_csv(\"diet_and_lifestyle_data.csv\")\n",
    "\n",
    "# Handle Categorical Features (One-Hot Encoding)\n",
    "# Create separate encoders for each categorical feature\n",
    "smoker_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "stress_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "preexisting_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "smoker_encoded = smoker_encoder.fit_transform(df[['Smoker (Y/N)']])\n",
    "stress_encoded = stress_encoder.fit_transform(df[['Stress Level']])\n",
    "preexisting_encoded = preexisting_encoder.fit_transform(df[['Pre-Existing Conditions (Y/N)']])\n",
    "\n",
    "# Create encoded DataFrame for each categorical feature\n",
    "df_encoded_smoker = pd.DataFrame(smoker_encoded.toarray(), columns=smoker_encoder.get_feature_names_out())\n",
    "df_encoded_stress = pd.DataFrame(stress_encoded.toarray(), columns=stress_encoder.get_feature_names_out())\n",
    "df_encoded_preexisting = pd.DataFrame(preexisting_encoded.toarray(), columns=preexisting_encoder.get_feature_names_out())\n",
    "\n",
    "# Concatenate all encoded features\n",
    "df_encoded = pd.concat([df_encoded_smoker, df_encoded_stress, df_encoded_preexisting], axis=1)\n",
    "\n",
    "# Drop original categorical columns and concatenate encoded features with the original DataFrame\n",
    "df = df.drop(['Smoker (Y/N)', 'Stress Level', 'Pre-Existing Conditions (Y/N)'], axis=1)\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# Continue with the rest of your code for scaling, splitting, model building, and evaluation\n",
    "\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Split data\n",
    "X = df.drop('Life Expectancy', axis=1)\n",
    "y = df['Life Expectancy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Building Functions\n",
    "def build_rf_model():\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    return model\n",
    "\n",
    "def build_gbr_model():\n",
    "    model = GradientBoostingRegressor(n_estimators=100, random_state=42) \n",
    "    return model\n",
    "\n",
    "def build_xgb_model():\n",
    "    model = xgb.XGBRegressor(n_estimators=100, random_state=42) \n",
    "    return model\n",
    "\n",
    "# Experimentation\n",
    "models = {\n",
    "    \"Random Forest\": build_rf_model,\n",
    "    \"Gradient Boosting (GBR)\": build_gbr_model, \n",
    "    \"XGBoost\": build_xgb_model\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for model_name, model_fn in models.items():\n",
    "    model = model_fn()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    results[model_name] = {'rmse': rmse}\n",
    "\n",
    "# Print Results\n",
    "print(\"Experiment Results:\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: RMSE - {metrics['rmse']:.4f}\")\n",
    "\n",
    "# Determine the Best Model\n",
    "best_model_name = min(results, key=lambda k: results[k]['rmse'])\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Termianal Version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eda-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load the Data\n",
    "df = pd.read_csv(\"diet_and_lifestyle_data.csv\") \n",
    "\n",
    "# 2. Data Ranges & Basic Stats\n",
    "print(df.describe()) \n",
    "\n",
    "# 3. Handle Categorical Features (One-Hot Encoding)\n",
    "encoder = OneHotEncoder(handle_unknown='ignore') \n",
    "smoker_encoded = encoder.fit_transform(df[['Smoker (Y/N)']])\n",
    "stress_encoded = encoder.fit_transform(df[['Stress Level']]) \n",
    "preexisting_encoded = encoder.fit_transform(df[['Pre-Existing Conditions (Y/N)']])\n",
    "\n",
    "df_encoded = pd.DataFrame(smoker_encoded.toarray(), columns=[\"Smoker_No\", \"Smoker_Yes\"]) \n",
    "df_encoded = pd.concat([df_encoded, pd.DataFrame(stress_encoded.toarray(), columns=[\"Stress_Low\", \"Stress_Medium\", \"Stress_High\"])], axis=1)\n",
    "df_encoded = pd.concat([df_encoded, pd.DataFrame(preexisting_encoded.toarray(), columns=[\"PreExisting_No\", \"PreExisting_Yes\"])], axis=1)\n",
    "\n",
    "df = df.drop(['Smoker (Y/N)', 'Stress Level', 'Pre-Existing Conditions (Y/N)'], axis=1)\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# 4. Scale Numerical Features (Using MinMaxScaler)\n",
    "scaler = MinMaxScaler()  \n",
    "df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']] = scaler.fit_transform(df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']])\n",
    "\n",
    "# 5. Split data \n",
    "X = df.drop('Life Expectancy', axis=1)\n",
    "y = df['Life Expectancy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. EDA \n",
    "# ... (Code for previous distributions, correlations, etc.)\n",
    "\n",
    "\n",
    "# 7. Insights: Age Groups and Eating Habits\n",
    "df['Age Group'] = pd.cut(df['Age'], bins=[20, 35, 50, 65, 100], \n",
    "                             labels=['20-35', '36-50', '51-65', '65+'])\n",
    "\n",
    "for col in ['Meals/Day', 'Pulses(g)', 'Veg(g)', 'Fruit(g)', 'Processed Food(g)']:\n",
    "    sns.boxplot(x='Age Group', y=col, data=df, showmeans=True) \n",
    "    plt.title(f'Distribution of {col} by Age Group')\n",
    "    plt.show()\n",
    "\n",
    "# 8. Insights: Alcohol Consumption\n",
    "sns.displot(df, x='Alcohol(g)', kind='kde')\n",
    "plt.title('Distribution of Alcohol Consumption')\n",
    "plt.show()\n",
    "\n",
    "sns.catplot(x='Smoker_Yes', y='Alcohol(g)', kind='box', data=df, showmeans=True) \n",
    "plt.title('Alcohol Consumption for Smokers (vs. Non-Smokers)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 9. Insights: Overall healthy pattern\n",
    "def calculate_healthy_index(row):\n",
    "    # Replace with your logic to define healthy eating\n",
    "    # Example (very simple):\n",
    "    if row['Veg(g)'] > 0.5 and row['Fruit(g)'] > 0.5 and row['Processed Food(g)'] < 0.2:  \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Healthy_Index'] = df.apply(calculate_healthy_index, axis=1) \n",
    "\n",
    "sns.boxplot(x='Age Group', y='Healthy_Index', data=df, showmeans=True)\n",
    "plt.title('Healthy Eating Index by Age Group')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eda-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load the Data\n",
    "df = pd.read_csv(\"diet_and_lifestyle_data.csv\") \n",
    "\n",
    "# 2. Data Ranges & Basic Stats\n",
    "print(df.describe()) \n",
    "print(df.isna().sum())  # Check for missing values\n",
    "\n",
    "# 3. Handle Categorical Features (One-Hot Encoding)\n",
    "encoder = OneHotEncoder(handle_unknown='ignore') \n",
    "smoker_encoded = encoder.fit_transform(df[['Smoker (Y/N)']])\n",
    "stress_encoded = encoder.fit_transform(df[['Stress Level']]) \n",
    "preexisting_encoded = encoder.fit_transform(df[['Pre-Existing Conditions (Y/N)']])\n",
    "\n",
    "df_encoded = pd.DataFrame(smoker_encoded.toarray(), columns=[\"Smoker_No\", \"Smoker_Yes\"]) \n",
    "df_encoded = pd.concat([df_encoded, pd.DataFrame(stress_encoded.toarray(), columns=[\"Stress_Low\", \"Stress_Medium\", \"Stress_High\"])], axis=1)\n",
    "df_encoded = pd.concat([df_encoded, pd.DataFrame(preexisting_encoded.toarray(), columns=[\"PreExisting_No\", \"PreExisting_Yes\"])], axis=1)\n",
    "\n",
    "df = df.drop(['Smoker (Y/N)', 'Stress Level', 'Pre-Existing Conditions (Y/N)'], axis=1)\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# 4. Scale Numerical Features (Using MinMaxScaler)\n",
    "scaler = MinMaxScaler()\n",
    "df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']] = scaler.fit_transform(df[['Meals/Day','Pulses(g)','Rice(g)','Protein(g)','Alcohol(g)','Veg(g)','Fruit(g)','Processed Food(g)','Exercise (hrs/week)','Sleep (hrs/night)','Age']])\n",
    "\n",
    "# 5. Split data \n",
    "X = df.drop('Life Expectancy', axis=1)\n",
    "y = df['Life Expectancy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. EDA \n",
    "# Distributions of Numerical Features:\n",
    "for col in X.select_dtypes(include='number'): \n",
    "    sns.displot(x=col, data=df, kind='kde')  \n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()\n",
    "\n",
    "# Correlations:\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm') \n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# 7. Insights: Age Groups and Eating Habits\n",
    "df['Age Group'] = pd.cut(df['Age'], bins=[20, 35, 50, 65, 100], \n",
    "                             labels=['20-35', '36-50', '51-65', '65+'])\n",
    "for col in ['Meals/Day', 'Pulses(g)', 'Veg(g)', 'Fruit(g)', 'Processed Food(g)']:\n",
    "    sns.boxplot(x='Age Group', y=col, data=df, showmeans=True) \n",
    "    plt.title(f'Distribution of {col} by Age Group')\n",
    "    plt.show()\n",
    "\n",
    "# 8. Insights: Alcohol Consumption\n",
    "sns.displot(df, x='Alcohol(g)', kind='kde')\n",
    "plt.title('Distribution of Alcohol Consumption')\n",
    "plt.show()\n",
    "\n",
    "sns.catplot(x='Smoker_Yes', y='Alcohol(g)', kind='box', data=df, showmeans=True) \n",
    "plt.title('Alcohol Consumption for Smokers (vs. Non-Smokers)')\n",
    "plt.show()\n",
    "\n",
    "# 9. Insights: Overall healthy pattern\n",
    "def calculate_healthy_index(row):\n",
    "    # Replace with your logic to define healthy eating\n",
    "    if row['Veg(g)'] > 0.5 and row['Fruit(g)'] > 0.5 and row['Processed Food(g)'] < 0.2:  \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Healthy_Index'] = df.apply(calculate_healthy_index, axis=1) \n",
    "\n",
    "sns.boxplot(x='Age Group', y='Healthy_Index', data=df, showmeans=True)\n",
    "plt.title('Healthy Eating Index by Age Group')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_user_input():\n",
    "#     data = {}\n",
    "#     data['Meals/Day'] = int(input(\"Enter meals per day: \"))\n",
    "#     data['Pulses(g)'] = int(input(\"Enter pulses intake (in grams): \"))\n",
    "#     data['Rice(g)'] = int(input(\"Enter rice intake (in grams): \"))\n",
    "#     data['Protein(g)'] = int(input(\"Enter protein intake (in grams): \"))\n",
    "#     data['Alcohol(g)'] = int(input(\"Enter alcohol intake (in grams): \"))\n",
    "#     data['Veg(g)'] = int(input(\"Enter vegetable intake (in grams): \"))\n",
    "#     data['Fruit(g)'] = int(input(\"Enter fruit intake (in grams): \"))\n",
    "#     data['Processed Food(g)'] = int(input(\"Enter processed food intake (in grams): \"))\n",
    "#     data['Exercise (hrs/week)'] = float(input(\"Enter exercise hours per week: \"))\n",
    "#     data['Sleep (hrs/night)'] = float(input(\"Enter sleep hours per night: \"))\n",
    "#     data['Age'] = int(input(\"Enter your age: \"))\n",
    "#     data['Smoker (Y/N)'] = input(\"Do you smoke? (Y/N): \")\n",
    "#     data['Stress Level'] = input(\"Enter your stress level (Low/Medium/High): \")\n",
    "#     data['Pre-Existing Conditions (Y/N)'] = input(\"Do you have pre-existing conditions? (Y/N): \")\n",
    "#     return data\n",
    "\n",
    "# # Get user input\n",
    "# user_data = get_user_input()\n",
    "\n",
    "# # Predict life expectancy\n",
    "# predicted_life_expectancy = predict_life_expectancy(user_data)\n",
    "\n",
    "# # Display the result\n",
    "# print(\"Your predicted life expectancy is:\", predicted_life_expectancy, \"years\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tkinter as tk\n",
    "# from tkinter import messagebox\n",
    "\n",
    "# def get_user_input():\n",
    "#     data = {}\n",
    "#     data['Meals/Day'] = int(meals_per_day_entry.get())\n",
    "#     data['Pulses(g)'] = int(pulses_entry.get())\n",
    "#     data['Rice(g)'] = int(rice_entry.get())\n",
    "#     data['Protein(g)'] = int(protein_entry.get())\n",
    "#     data['Alcohol(g)'] = int(alcohol_entry.get())\n",
    "#     data['Veg(g)'] = int(veg_entry.get())\n",
    "#     data['Fruit(g)'] = int(fruit_entry.get())\n",
    "#     data['Processed Food(g)'] = int(processed_food_entry.get())\n",
    "#     data['Exercise (hrs/week)'] = float(exercise_entry.get())\n",
    "#     data['Sleep (hrs/night)'] = float(sleep_entry.get())\n",
    "#     data['Age'] = int(age_entry.get())\n",
    "#     data['Smoker (Y/N)'] = smoker_entry.get()\n",
    "#     data['Stress Level'] = stress_level_entry.get()\n",
    "#     data['Pre-Existing Conditions (Y/N)'] = pre_existing_conditions_entry.get()\n",
    "#     return data\n",
    "\n",
    "# def submit_form():\n",
    "#     user_data = get_user_input()\n",
    "#     predicted_life_expectancy = predict_life_expectancy(user_data)\n",
    "#     messagebox.showinfo(\"Result\", \"Your predicted life expectancy is: \" + str(predicted_life_expectancy) + \" years\")\n",
    "\n",
    "# root = tk.Tk()\n",
    "\n",
    "# # Create your entry fields here\n",
    "# meals_per_day_entry = tk.Entry(root)\n",
    "# pulses_entry = tk.Entry(root)\n",
    "# rice_entry = tk.Entry(root)\n",
    "# protein_entry = tk.Entry(root)\n",
    "# alcohol_entry = tk.Entry(root)\n",
    "# veg_entry = tk.Entry(root)\n",
    "# fruit_entry = tk.Entry(root)\n",
    "# processed_food_entry = tk.Entry(root)\n",
    "# exercise_entry = tk.Entry(root)\n",
    "# sleep_entry = tk.Entry(root)\n",
    "# age_entry = tk.Entry(root)\n",
    "# smoker_entry = tk.Entry(root)\n",
    "# stress_level_entry = tk.Entry(root)\n",
    "# pre_existing_conditions_entry = tk.Entry(root)\n",
    "\n",
    "# # Pack your entry fields here\n",
    "# meals_per_day_entry.pack()\n",
    "# pulses_entry.pack()\n",
    "# rice_entry.pack()\n",
    "# protein_entry.pack()\n",
    "# alcohol_entry.pack()\n",
    "# veg_entry.pack()\n",
    "# fruit_entry.pack()\n",
    "# processed_food_entry.pack()\n",
    "# exercise_entry.pack()\n",
    "# sleep_entry.pack()\n",
    "# age_entry.pack()\n",
    "# smoker_entry.pack()\n",
    "# stress_level_entry.pack()\n",
    "# pre_existing_conditions_entry.pack()\n",
    "\n",
    "# submit_button = tk.Button(root, text=\"Submit\", command=submit_form)\n",
    "# submit_button.pack()\n",
    "\n",
    "# root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tkinter as tk\n",
    "# from tkinter import messagebox\n",
    "\n",
    "# def get_user_input():\n",
    "#     data = {}\n",
    "#     data['Meals/Day'] = int(meals_per_day_entry.get())\n",
    "#     data['Pulses(g)'] = int(pulses_entry.get())\n",
    "#     data['Rice(g)'] = int(rice_entry.get())\n",
    "#     data['Protein(g)'] = int(protein_entry.get())\n",
    "#     data['Alcohol(g)'] = int(alcohol_entry.get())\n",
    "#     data['Veg(g)'] = int(veg_entry.get())\n",
    "#     data['Fruit(g)'] = int(fruit_entry.get())\n",
    "#     data['Processed Food(g)'] = int(processed_food_entry.get())\n",
    "#     data['Exercise (hrs/week)'] = float(exercise_entry.get())\n",
    "#     data['Sleep (hrs/night)'] = float(sleep_entry.get())\n",
    "#     data['Age'] = int(age_entry.get())\n",
    "#     data['Smoker (Y/N)'] = smoker_entry.get()\n",
    "#     data['Stress Level'] = stress_level_entry.get()\n",
    "#     data['Pre-Existing Conditions (Y/N)'] = pre_existing_conditions_entry.get()\n",
    "#     return data\n",
    "\n",
    "# def submit_form():\n",
    "#     user_data = get_user_input()\n",
    "#     predicted_life_expectancy = predict_life_expectancy(user_data)\n",
    "#     messagebox.showinfo(\"Result\", \"Your predicted life expectancy is: \" + str(predicted_life_expectancy) + \" years\")\n",
    "\n",
    "# # Create the main window\n",
    "# window = tk.Tk()\n",
    "# window.title(\"Life Expectancy Predictor\")\n",
    "\n",
    "# # Create labels and input fields\n",
    "# # Create labels and input fields\n",
    "# tk.Label(window, text=\"Meals per day:\").grid(row=0, column=0)\n",
    "# meals_entry = tk.Entry(window)\n",
    "# meals_entry.grid(row=0, column=1)\n",
    "\n",
    "# tk.Label(window, text=\"Pulses intake (grams):\").grid(row=1, column=0)\n",
    "# pulses_entry = tk.Entry(window)\n",
    "# pulses_entry.grid(row=1, column=1)\n",
    "\n",
    "# tk.Label(window, text=\"Rice intake (grams):\").grid(row=2, column=0)\n",
    "# rice_entry = tk.Entry(window)\n",
    "# rice_entry.grid(row=2, column=1)\n",
    "\n",
    "# tk.Label(window, text=\"Protein intake (grams):\").grid(row=3, column=0)\n",
    "# protein_entry = tk.Entry(window)\n",
    "# protein_entry.grid(row=3, column=1)\n",
    "\n",
    "# tk.Label(window, text=\"Alcohol intake (grams):\").grid(row=4, column=0)\n",
    "# alcohol_entry = tk.Entry(window)\n",
    "# alcohol_entry.grid(row=4, column=1)\n",
    "\n",
    "# tk.Label(window, text=\"Vegetable intake (grams):\").grid(row=5, column=0)\n",
    "# veg_entry = tk.Entry(window)\n",
    "# veg_entry.grid(row=5, column=1)\n",
    "\n",
    "# tk.Label(window, text=\"Fruit intake (grams):\").grid(row=6, column=0)\n",
    "# fruit_entry = tk.Entry(window)\n",
    "# fruit_entry.grid(row=6, column=1)\n",
    "\n",
    "# tk.Label(window, text=\"Processed food intake (grams):\").grid(row=7, column=0)\n",
    "# processed_entry = tk.Entry(window)\n",
    "# processed_entry.grid(row=7, column=1)\n",
    "\n",
    "# tk.Label(window, text=\"Exercise hours per week:\").grid(row=8, column=0)\n",
    "# exercise_entry = tk.Entry(window)\n",
    "# exercise_entry.grid(row=8, column=1)\n",
    "\n",
    "# tk.Label(window, text=\"Sleep hours per night:\").grid(row=9, column=0)\n",
    "# sleep_entry = tk.Entry(window)\n",
    "# sleep_entry.grid(row=9, column=1)\n",
    "\n",
    "# tk.Label(window, text=\"Age:\").grid(row=10, column=0)\n",
    "# age_entry = tk.Entry(window)\n",
    "# age_entry.grid(row=10, column=1)\n",
    "\n",
    "# tk.Label(window, text=\"Do you smoke? (Y/N):\").grid(row=11, column=0)\n",
    "# smoker_entry = tk.Entry(window)\n",
    "# smoker_entry.grid(row=11, column=1)\n",
    "\n",
    "# tk.Label(window, text=\"Stress level (Low/Medium/High):\").grid(row=12, column=0)\n",
    "# stress_entry = tk.Entry(window)\n",
    "# stress_entry.grid(row=12, column=1)\n",
    "\n",
    "# tk.Label(window, text=\"Pre-existing conditions? (Y/N):\").grid(row=13, column=0)\n",
    "# preexisting_entry = tk.Entry(window)\n",
    "# preexisting_entry.grid(row=13, column=1)\n",
    "\n",
    "# # Repeat the above two lines for each field\n",
    "# # ...\n",
    "\n",
    "# # Create a submit button\n",
    "# submit_button = tk.Button(window, text=\"Submit\", command=submit_form)\n",
    "# submit_button.grid(row=14, column=1)  # Adjust the row number as needed\n",
    "\n",
    "# window.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tinker Ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "def submit_form():\n",
    "    data = {}\n",
    "    data['Meals/Day'] = int(meals_entry.get())\n",
    "    data['Pulses(g)'] = int(pulses_entry.get())\n",
    "    data['Rice(g)'] = int(rice_entry.get())\n",
    "    data['Protein(g)'] = int(protein_entry.get())\n",
    "    data['Alcohol(g)'] = int(alcohol_entry.get())\n",
    "    data['Veg(g)'] = int(veg_entry.get())\n",
    "    data['Fruit(g)'] = int(fruit_entry.get())\n",
    "    data['Processed Food(g)'] = int(processed_entry.get())\n",
    "    data['Exercise (hrs/week)'] = float(exercise_entry.get())\n",
    "    data['Sleep (hrs/night)'] = float(sleep_entry.get())\n",
    "    data['Age'] = int(age_entry.get())\n",
    "    data['Smoker (Y/N)'] = smoker_entry.get()\n",
    "    data['Stress Level'] = stress_entry.get()\n",
    "    data['Pre-Existing Conditions (Y/N)'] = preexisting_entry.get()\n",
    "\n",
    "    predicted_life_expectancy = predict_life_expectancy(data)\n",
    "    messagebox.showinfo(\"Result\", \"Your predicted life expectancy is: \" + str(predicted_life_expectancy) + \" years\")\n",
    "\n",
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Life Expectancy Predictor\")\n",
    "\n",
    "# Create labels and input fields\n",
    "tk.Label(window, text=\"Meals per day:\").grid(row=0, column=0)\n",
    "meals_entry = tk.Entry(window)\n",
    "meals_entry.grid(row=0, column=1)\n",
    "\n",
    "tk.Label(window, text=\"Pulses intake (grams):\").grid(row=1, column=0)\n",
    "pulses_entry = tk.Entry(window)\n",
    "pulses_entry.grid(row=1, column=1)\n",
    "\n",
    "tk.Label(window, text=\"Rice intake (grams):\").grid(row=2, column=0)\n",
    "rice_entry = tk.Entry(window)\n",
    "rice_entry.grid(row=2, column=1)\n",
    "\n",
    "tk.Label(window, text=\"Protein intake (grams):\").grid(row=3, column=0)\n",
    "protein_entry = tk.Entry(window)\n",
    "protein_entry.grid(row=3, column=1)\n",
    "\n",
    "tk.Label(window, text=\"Alcohol intake (grams):\").grid(row=4, column=0)\n",
    "alcohol_entry = tk.Entry(window)\n",
    "alcohol_entry.grid(row=4, column=1)\n",
    "\n",
    "tk.Label(window, text=\"Vegetable intake (grams):\").grid(row=5, column=0)\n",
    "veg_entry = tk.Entry(window)\n",
    "veg_entry.grid(row=5, column=1)\n",
    "\n",
    "tk.Label(window, text=\"Fruit intake (grams):\").grid(row=6, column=0)\n",
    "fruit_entry = tk.Entry(window)\n",
    "fruit_entry.grid(row=6, column=1)\n",
    "\n",
    "tk.Label(window, text=\"Processed food intake (grams):\").grid(row=7, column=0)\n",
    "processed_entry = tk.Entry(window)\n",
    "processed_entry.grid(row=7, column=1)\n",
    "\n",
    "tk.Label(window, text=\"Exercise hours per week:\").grid(row=8, column=0)\n",
    "exercise_entry = tk.Entry(window)\n",
    "exercise_entry.grid(row=8, column=1)\n",
    "\n",
    "tk.Label(window, text=\"Sleep hours per night:\").grid(row=9, column=0)\n",
    "sleep_entry = tk.Entry(window)\n",
    "sleep_entry.grid(row=9, column=1)\n",
    "\n",
    "tk.Label(window, text=\"Age:\").grid(row=10, column=0)\n",
    "age_entry = tk.Entry(window)\n",
    "age_entry.grid(row=10, column=1)\n",
    "\n",
    "tk.Label(window, text=\"Do you smoke? (Y/N):\").grid(row=11, column=0)\n",
    "smoker_entry = tk.Entry(window)\n",
    "smoker_entry.grid(row=11, column=1)\n",
    "\n",
    "tk.Label(window, text=\"Stress level (Low/Medium/High):\").grid(row=12, column=0)\n",
    "stress_entry = tk.Entry(window)\n",
    "stress_entry.grid(row=12, column=1)\n",
    "\n",
    "tk.Label(window, text=\"Pre-existing conditions? (Y/N):\").grid(row=13, column=0)\n",
    "preexisting_entry = tk.Entry(window)\n",
    "preexisting_entry.grid(row=13, column=1)\n",
    "\n",
    "# Create a submit button\n",
    "submit_button = tk.Button(window, text=\"Submit\", command=submit_form)\n",
    "submit_button.grid(row=14, column=1)  # Adjust the row number as needed\n",
    "\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
